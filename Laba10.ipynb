{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c5878eb-547d-4773-8bff-21e18a94236c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv('spam.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71cbe198-f1fe-4f60-965a-9f1dac54565e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   v1          5572 non-null   object\n",
      " 1   v2          5572 non-null   object\n",
      " 2   Unnamed: 2  50 non-null     object\n",
      " 3   Unnamed: 3  12 non-null     object\n",
      " 4   Unnamed: 4  6 non-null      object\n",
      "dtypes: object(5)\n",
      "memory usage: 217.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e4b2573-0dcb-40b2-9e63-be775f3291bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "452618b7-9023-4afd-9b4d-f54c8e3482fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 2', axis=1)\n",
    "df = df.drop('Unnamed: 3', axis=1)\n",
    "df = df.drop('Unnamed: 4', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52a34bf7-3064-4c8b-8d6b-5d64a04f87f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   v1      5572 non-null   object\n",
      " 1   v2      5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e0b47c6-78db-48a3-bac2-aac2a6078053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b62b2014-6f81-4830-86d2-112c0c983534",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['v2']\n",
    "y = df['v1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f1688e1-916b-4abc-971c-393b31471520",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86951808-33da-4b1d-9177-2adaf9b818c7",
   "metadata": {},
   "source": [
    "### Решить задачу классификации с понижением размерности. Использовать самостоятельно реализованные модели из предыдущих ЛР."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a7fd726-6b31-4e04-b0f0-a27530be7fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, RFE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE, Isomap\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d625b73c-a48c-4ee6-a9b5-0cd24eff902f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_class(X, y):\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "  bag = BaggingClassifier().fit(X_train, y_train)\n",
    "  print(classification_report(y_test, bag.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c59255f1-7867-4940-b5f2-a811015bc108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Создание экземпляра CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Преобразование текстовых данных в матрицу признаков\n",
    "X_bow = vectorizer.fit_transform(X)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Создание экземпляра TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Преобразование текстовых данных в матрицу признаков\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "# 1. SelectKBest\n",
    "selector = SelectKBest(k=2)  # количество наиболее значимых признаков\n",
    "X_SelectKBest_classifier1 = selector.fit_transform(X_bow, y)\n",
    "X_SelectKBest_classifier2 = selector.fit_transform(X_tfidf, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d97d138-98e3-4cc2-9437-e861fa6713ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.95      0.96      0.96       917\n",
      "        spam       0.66      0.60      0.63       117\n",
      "\n",
      "    accuracy                           0.92      1034\n",
      "   macro avg       0.80      0.78      0.79      1034\n",
      "weighted avg       0.92      0.92      0.92      1034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_class(X_SelectKBest_classifier1, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f68ccc5-8828-4405-9897-0bd16519fdc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.91      1.00      0.95       917\n",
      "        spam       0.90      0.24      0.38       117\n",
      "\n",
      "    accuracy                           0.91      1034\n",
      "   macro avg       0.91      0.62      0.67      1034\n",
      "weighted avg       0.91      0.91      0.89      1034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_class(X_SelectKBest_classifier2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "462dfe1f-1c96-4bb0-bd73-6bb0720eb5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. RFE (Recursive Feature Elimination)\n",
    "estimator = BaggingClassifier()\n",
    "selector = RFE(estimator, n_features_to_select=5)  # количество выбранных признаков (n_features_to_select)\n",
    "X_RFE_classifier1 = selector.fit_transform(X_SelectKBest_classifier1, y)\n",
    "X_RFE_classifier2 = selector.fit_transform(X_SelectKBest_classifier2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf9c1e95-273e-4a6a-8126-237e7dd94b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.95      0.96      0.96       917\n",
      "        spam       0.66      0.60      0.63       117\n",
      "\n",
      "    accuracy                           0.92      1034\n",
      "   macro avg       0.80      0.78      0.79      1034\n",
      "weighted avg       0.92      0.92      0.92      1034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_class(X_RFE_classifier1, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cad8a91b-b686-4d68-9211-9f9aabe02709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.91      1.00      0.95       917\n",
      "        spam       0.90      0.24      0.38       117\n",
      "\n",
      "    accuracy                           0.91      1034\n",
      "   macro avg       0.91      0.62      0.67      1034\n",
      "weighted avg       0.91      0.91      0.89      1034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_class(X_RFE_classifier2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a5fde6f-45f3-44b2-93f1-8f76f033ede1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\environment\\venv\\lib\\site-packages\\sklearn\\manifold\\_isomap.py:373: UserWarning: The number of connected components of the neighbors graph is 6 > 1. Completing the graph to fit Isomap might be slow. Increase the number of neighbors to avoid this issue.\n",
      "  self._fit_transform(X)\n",
      "D:\\environment\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "D:\\environment\\venv\\lib\\site-packages\\sklearn\\manifold\\_isomap.py:373: UserWarning: The number of connected components of the neighbors graph is 4 > 1. Completing the graph to fit Isomap might be slow. Increase the number of neighbors to avoid this issue.\n",
      "  self._fit_transform(X)\n",
      "D:\\environment\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n"
     ]
    }
   ],
   "source": [
    "# 6. Isomap\n",
    "isomap = Isomap(n_components=10)  # количество компонент (n_components)\n",
    "X_Isomap_classifier1 = isomap.fit_transform(X_bow)\n",
    "X_Isomap_classifier2 = isomap.fit_transform(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36bb0374-d058-42b6-b892-a5f74c5987a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.94      0.98      0.96       917\n",
      "        spam       0.75      0.55      0.63       117\n",
      "\n",
      "    accuracy                           0.93      1034\n",
      "   macro avg       0.85      0.76      0.80      1034\n",
      "weighted avg       0.92      0.93      0.92      1034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_class(X_Isomap_classifier1, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a58d3764-67f0-4d2b-a005-1a767bcd92fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.93      0.97      0.95       917\n",
      "        spam       0.62      0.43      0.51       117\n",
      "\n",
      "    accuracy                           0.91      1034\n",
      "   macro avg       0.78      0.70      0.73      1034\n",
      "weighted avg       0.90      0.91      0.90      1034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_class(X_Isomap_classifier2, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5848609-5836-4cd0-b2aa-57f1a7904acf",
   "metadata": {},
   "source": [
    "### Решить задачу тематического моделирования с помощью LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45434e01-c8c4-4de4-8a04-d19bc490bca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.0/1.5 MB 1.3 MB/s eta 0:00:02\n",
      "     -- ------------------------------------- 0.1/1.5 MB 1.1 MB/s eta 0:00:02\n",
      "     ---- ----------------------------------- 0.2/1.5 MB 1.1 MB/s eta 0:00:02\n",
      "     ----- ---------------------------------- 0.2/1.5 MB 1.1 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 0.4/1.5 MB 1.5 MB/s eta 0:00:01\n",
      "     -------------- ------------------------- 0.6/1.5 MB 1.9 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 0.7/1.5 MB 2.2 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 1.0/1.5 MB 2.6 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 1.0/1.5 MB 2.7 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 1.0/1.5 MB 2.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.5/1.5 MB 3.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: click in d:\\environment\\venv\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in d:\\environment\\venv\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2023.12.25-cp310-cp310-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.0/42.0 kB ? eta 0:00:00\n",
      "Requirement already satisfied: tqdm in d:\\environment\\venv\\lib\\site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: colorama in d:\\environment\\venv\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading regex-2023.12.25-cp310-cp310-win_amd64.whl (269 kB)\n",
      "   ---------------------------------------- 0.0/269.5 kB ? eta -:--:--\n",
      "   ---------------------------------------  266.2/269.5 kB 8.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 269.5/269.5 kB 5.5 MB/s eta 0:00:00\n",
      "Installing collected packages: regex, nltk\n",
      "Successfully installed nltk-3.8.1 regex-2023.12.25\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c6cc840e-2cda-4e15-a2e6-41981be83170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.2-cp310-cp310-win_amd64.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in d:\\environment\\venv\\lib\\site-packages (from gensim) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.7.0 in d:\\environment\\venv\\lib\\site-packages (from gensim) (1.10.1)\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "  Downloading smart_open-6.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Downloading gensim-4.3.2-cp310-cp310-win_amd64.whl (24.0 MB)\n",
      "   ---------------------------------------- 0.0/24.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/24.0 MB 1.3 MB/s eta 0:00:19\n",
      "   ---------------------------------------- 0.1/24.0 MB 1.1 MB/s eta 0:00:23\n",
      "   ---------------------------------------- 0.2/24.0 MB 1.1 MB/s eta 0:00:22\n",
      "   ---------------------------------------- 0.2/24.0 MB 1.1 MB/s eta 0:00:23\n",
      "    --------------------------------------- 0.3/24.0 MB 1.4 MB/s eta 0:00:17\n",
      "    --------------------------------------- 0.6/24.0 MB 2.1 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 0.8/24.0 MB 2.5 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 1.0/24.0 MB 2.7 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 1.0/24.0 MB 2.7 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 1.0/24.0 MB 2.7 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 1.0/24.0 MB 2.7 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 1.0/24.0 MB 2.7 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 1.0/24.0 MB 2.7 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 1.0/24.0 MB 2.7 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 1.0/24.0 MB 2.7 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 1.0/24.0 MB 2.7 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 1.8/24.0 MB 2.2 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 2.5/24.0 MB 3.1 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 2.7/24.0 MB 3.0 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 2.8/24.0 MB 3.1 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 2.9/24.0 MB 3.0 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 3.2/24.0 MB 3.1 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 3.5/24.0 MB 3.3 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 3.9/24.0 MB 3.5 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 4.3/24.0 MB 3.7 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 4.5/24.0 MB 3.7 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 4.9/24.0 MB 3.9 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 5.2/24.0 MB 4.0 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 5.6/24.0 MB 4.2 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 5.9/24.0 MB 4.3 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 6.2/24.0 MB 4.3 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 6.6/24.0 MB 4.4 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 7.0/24.0 MB 4.5 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 7.4/24.0 MB 4.7 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 7.8/24.0 MB 4.8 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 8.2/24.0 MB 4.9 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 8.6/24.0 MB 5.0 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 9.0/24.0 MB 5.1 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 9.4/24.0 MB 5.2 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 9.8/24.0 MB 5.3 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 10.1/24.0 MB 5.3 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 10.4/24.0 MB 5.7 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 10.8/24.0 MB 6.0 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 11.3/24.0 MB 8.1 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 11.7/24.0 MB 7.8 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 12.1/24.0 MB 7.6 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 12.5/24.0 MB 7.4 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 12.9/24.0 MB 7.5 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 13.2/24.0 MB 7.9 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 13.6/24.0 MB 8.0 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 14.0/24.0 MB 8.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 14.3/24.0 MB 8.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 14.6/24.0 MB 7.9 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 15.0/24.0 MB 8.0 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 15.4/24.0 MB 8.2 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 15.7/24.0 MB 8.1 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 16.1/24.0 MB 8.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 16.5/24.0 MB 8.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 16.9/24.0 MB 8.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 17.3/24.0 MB 8.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 17.7/24.0 MB 8.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 18.1/24.0 MB 8.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 18.4/24.0 MB 8.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 18.8/24.0 MB 8.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 19.2/24.0 MB 8.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 19.6/24.0 MB 8.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 20.1/24.0 MB 8.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 20.5/24.0 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 20.9/24.0 MB 8.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.3/24.0 MB 8.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 21.7/24.0 MB 8.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.1/24.0 MB 8.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 22.5/24.0 MB 8.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 22.9/24.0 MB 8.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.3/24.0 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  23.7/24.0 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.0/24.0 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.0/24.0 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.0/24.0 MB 7.8 MB/s eta 0:00:00\n",
      "Downloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
      "   ---------------------------------------- 0.0/57.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 57.0/57.0 kB 1.5 MB/s eta 0:00:00\n",
      "Installing collected packages: smart-open, gensim\n",
      "Successfully installed gensim-4.3.2 smart-open-6.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec6ffb9d-3dfe-4809-bc4e-bab764ba339e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Полина\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim import corpora\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7851c51b-e038-4f75-8155-6e9164e7b158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание объекта CountVectorizer для извлечения признаков\n",
    "vectorizer = CountVectorizer(max_features=1000,   # Ограничение на максимальное количество признаков\n",
    "                             stop_words='english',  # Игнорирование стоп-слов\n",
    "                             max_df=0.5,  # Игнорирование терминов, которые появляются в более чем 50% документов\n",
    "                             min_df=2)  # Игнорирование терминов, которые появляются в менее чем 2 документах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "acff7ffa-e427-4432-9396-674c0f584629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование текстовых данных в матрицу признаков\n",
    "X_features = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ef68cd3e-d5d6-42ad-b686-a56eaa546a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание модели LDA\n",
    "num_topics = 10  # Количество тем\n",
    "lda_model = LatentDirichletAllocation(n_components=num_topics, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a9bc2e4-efa0-4a37-a048-720ec7fde8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение модели LDA\n",
    "lda_model.fit(X_features)\n",
    "\n",
    "# Получение самых вероятных слов для каждой темы\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "top_words = 10  # Количество верхних слов для вывода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6f39aa31-4905-4dc7-8794-73e4a295ebd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тема #1:\n",
      "['know', 'did', 'right', 'yes', 'just', 'tonight', 'say', 'gonna', 'phone', 'like']\n",
      "\n",
      "Тема #2:\n",
      "['lor', 'got', 'ok', 'oh', 'wat', 'pls', 'dun', 'wan', 'ask', 'ìï']\n",
      "\n",
      "Тема #3:\n",
      "['tell', 'just', 'don', 'yeah', 'sure', 'time', 'got', 'ok', 'going', 'll']\n",
      "\n",
      "Тема #4:\n",
      "['like', 'going', 'da', 'way', 'feel', 'think', 'time', 'ya', 'life', 'make']\n",
      "\n",
      "Тема #5:\n",
      "['claim', 'prize', 'won', 'number', 'cash', 'www', 'urgent', 'win', 'com', 'txt']\n",
      "\n",
      "Тема #6:\n",
      "['good', 'love', 'day', 'ì_', 'hi', 'hope', 'happy', 'morning', 'babe', 'miss']\n",
      "\n",
      "Тема #7:\n",
      "['ll', 'just', 'sorry', 'need', 'want', 'come', 'sent', 'dont', 'later', 'time']\n",
      "\n",
      "Тема #8:\n",
      "['txt', 'home', 'new', 'ur', 'chat', '150p', 'send', 'stop', 'week', 'free']\n",
      "\n",
      "Тема #9:\n",
      "['gt', 'lt', 'ur', 'ok', 'reply', 'msg', 'send', 'sms', 'heart', 'text']\n",
      "\n",
      "Тема #10:\n",
      "['free', 'text', 'know', 'mobile', 'stop', 'let', 'phone', 'reply', 'aight', 'txt']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for topic_idx, topic in enumerate(lda_model.components_):\n",
    "    top_feature_indices = topic.argsort()[:-top_words - 1:-1]\n",
    "    top_features = [feature_names[i] for i in top_feature_indices]\n",
    "    print(f\"Тема #{topic_idx + 1}:\")\n",
    "    print(top_features)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a9d4578-f710-4639-8d3a-f882f68cbd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получение распределения тем для каждого документа\n",
    "topic_distribution = lda_model.transform(X_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f1186599-c1a3-47a1-b6b7-cb5b509f1746",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_likely_topics = topic_distribution.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "776662f5-c457-4446-acc1-19afe1ca6021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 4, ..., 0, 0, 6], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_likely_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a5aa47e3-e6ca-4d69-9e12-6f48c0881f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['most_likely_topic'] = most_likely_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f595618-58ee-46a4-ae19-40f2235055f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>most_likely_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5164</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5165</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5166</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5168</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5169 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        v1                                                 v2  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...   \n",
       "1      ham                      Ok lar... Joking wif u oni...   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3      ham  U dun say so early hor... U c already then say...   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "...    ...                                                ...   \n",
       "5164  spam  This is the 2nd time we have tried 2 contact u...   \n",
       "5165   ham              Will Ì_ b going to esplanade fr home?   \n",
       "5166   ham  Pity, * was in mood for that. So...any other s...   \n",
       "5167   ham  The guy did some bitching but I acted like i'd...   \n",
       "5168   ham                         Rofl. Its true to its name   \n",
       "\n",
       "      most_likely_topic  \n",
       "0                     0  \n",
       "1                     3  \n",
       "2                     4  \n",
       "3                     0  \n",
       "4                     0  \n",
       "...                 ...  \n",
       "5164                  4  \n",
       "5165                  5  \n",
       "5166                  0  \n",
       "5167                  0  \n",
       "5168                  6  \n",
       "\n",
       "[5169 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044fa0bd-3964-4d01-beeb-fd50f988f850",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
